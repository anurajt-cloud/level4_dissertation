{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from ECG.eager_ops import expected_gradients as eg\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./eval_data_10k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_ph',\n",
       " 'cnn_ph_eg',\n",
       " 'cnn_pl',\n",
       " 'cnn_pl_eg',\n",
       " 'lstm_ph',\n",
       " 'lstm_ph_eg',\n",
       " 'lstm_pl',\n",
       " 'lstm_pl_eg',\n",
       " 'svc_ph',\n",
       " 'svc_pl',\n",
       " 'teset_x.npy',\n",
       " 'teset_y.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the confusion matrices for PH\n",
    "# cnn_ph_cv1 = np.load(path+ph_folders[0]+\"/cms_cv1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmss(foldername, tname):\n",
    "    if tname == \"ph\":\n",
    "        cmss = []\n",
    "        for i in range(1,11):\n",
    "            cmss.append(np.load(path+foldername+\"/cms_cv\"+str(i)+\".npy\").reshape(1,8,8))\n",
    "        cmss = np.concatenate(tuple(cmss), axis=0)\n",
    "        return cmss\n",
    "    elif tname == \"pl\":\n",
    "        return np.load(path+foldername+\"/cms.npy\")\n",
    "\n",
    "def get_results(foldername, tname):\n",
    "    if tname == \"ph\":\n",
    "        results = []\n",
    "        for i in range(1,11):\n",
    "            results.append(np.load(path+foldername+\"/results_cv\"+str(i)+\".npy\", allow_pickle=True)[1:6])\n",
    "        return np.stack(tuple(results))\n",
    "    elif tname == \"pl\":\n",
    "        return np.load(path+foldername+\"/results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cm(cmss, name, fname):\n",
    "    categories=['N','L','R','V','A','F','f','/']\n",
    "    plt.figure(figsize=(10,7), dpi=300)\n",
    "    sns.heatmap(cmss.mean(axis=0), annot=True, xticklabels=categories, yticklabels=categories)\n",
    "    plt.title(name)\n",
    "    plt.savefig(\"./images/\"+fname,dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = get_cmss(\"cnn_ph\", \"ph\") done!\n",
    "# b = get_cmss(\"lstm_ph\", \"ph\") done!\n",
    "# c = get_cmss('cnn_ph_eg', \"ph\") done!\n",
    "# d = get_cmss('lstm_ph_eg', \"ph\")\n",
    "# s = get_cmss('svc_ph', \"ph\") done!\n",
    "# make_cm(a, \"CNN - Beat holdout Confusion Matrix\", \"cnn_ph\") done!\n",
    "# make_cm(b, \"LSTM - Beat holdout Confusion Matrix\", \"lstm_ph\") done!\n",
    "# make_cm(c, \"CNN - Beat holdout with ECG Confusion Matrix\", \"cnn_ph_eg\") done!\n",
    "# make_cm(d, \"LSTM - Beat holdout with ECG Confusion Matrix\",'lstm_ph_eg')\n",
    "# make_cm(s, \"SVC - Beat holdout Confusion Matrix\", \"svc_ph\") done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = get_cmss(\"cnn_pl\", \"pl\")\n",
    "# f = get_cmss(\"lstm_pl\", \"pl\")\n",
    "# g = get_cmss('cnn_pl_eg', \"pl\")\n",
    "# h = get_cmss('lstm_pl_eg', \"pl\")\n",
    "# t = get_cmss('svc_pl', \"pl\")\n",
    "# make_cm(e, \"CNN - Patient leaveout Confusion Matrix\", \"cnn_pl\")\n",
    "# make_cm(f, \"LSTM - Patient leaveout Confusion Matrix\", \"lstm_pl\")\n",
    "# make_cm(g, \"CNN - Patient leaveout with ECG Confusion Matrix\", 'cnn_pl_eg')\n",
    "# make_cm(h, \"LSTM - Patient leaveout with ECG Confusion Matrix\", 'lstm_pl_eg')\n",
    "# make_cm(t, \"SVC - Patient leaveout Confusion Matrix\", \"svc_pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.828 0.413 0.484 0.434 0.828]\n",
      "[0.81 0.446 0.472 0.428 0.81]\n",
      "[0.631 0.381 0.337 0.294 0.631]\n",
      "[0.655 0.386 0.309 0.279 0.655]\n"
     ]
    }
   ],
   "source": [
    "d_r = get_results(\"cnn_pl\", \"pl\")\n",
    "e_r = get_results(\"lstm_pl\", \"pl\")\n",
    "f_r = get_results('cnn_pl_eg', \"pl\")\n",
    "g_r = get_results('lstm_pl_eg', \"pl\")\n",
    "print(d_r[3][1:6])\n",
    "print(f_r[0][1:6])\n",
    "print(e_r[0][1:6])\n",
    "print(g_r[0][1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eg(m, dx, dy): \n",
    "  test_d = tf.data.Dataset.from_tensor_slices((dx,dy))\n",
    "  test_d = test_d.batch(200)\n",
    "  att = None\n",
    "  for i, (x_batch, y_batch) in enumerate(test_d):\n",
    "    if i==0:\n",
    "        att = eg(inputs=x_batch, labels=y_batch, model=m)\n",
    "    else:\n",
    "        att = np.append(att,eg(inputs=x_batch, labels=y_batch, model=m),axis=0)\n",
    "  return att\n",
    "\n",
    "def eg_att(foldername, tname):\n",
    "    if tname==\"ph\":\n",
    "        test_y = np.load(\"./eval_data_10k/teset_y.npy\", allow_pickle=True)\n",
    "        test_x = np.load(\"./eval_data_10k/teset_x.npy\", allow_pickle=True)\n",
    "        attributions = []\n",
    "        for i in range(1,11):\n",
    "            m = tf.keras.models.load_model(path+foldername+\"/Model_cv\"+str(i)+\".h5\")\n",
    "            dx = test_x[i-1].reshape(-1, test_x[i-1].shape[1], 1).astype(np.float32)\n",
    "            dy = tf.keras.utils.to_categorical(test_y[i-1].astype(np.float32))\n",
    "            attributions.append(cal_eg(m, dx, dy))\n",
    "        return attributions\n",
    "    elif tname==\"pl\":\n",
    "        test_c0 = np.genfromtxt('./Data/test_patients_fc.csv', delimiter=',')\n",
    "        test_c1 = np.genfromtxt('./Data/test_patients_sc.csv', delimiter=',')\n",
    "        test_x_c01 = np.concatenate((test_c0[:, :-2], test_c1[:, :-2]), axis=1)\n",
    "        test_y_c01 = np.concatenate((test_c0[:, -2:], test_c0[:, -2:]), axis=1)\n",
    "        dx = test_x_c01.reshape(-1, test_x_c01.shape[1], 1).astype('float32')\n",
    "        dy = tf.keras.utils.to_categorical(test_y_c01[:,0])\n",
    "        m = tf.keras.models.load_model(path+foldername+\"/Model0.h5\")\n",
    "        return cal_eg(m, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9902, 9) (9902, 920, 1)\n"
     ]
    }
   ],
   "source": [
    "# test_c0 = np.genfromtxt('./Data/test_patients_fc.csv', delimiter=',')\n",
    "# test_c1 = np.genfromtxt('./Data/test_patients_sc.csv', delimiter=',')\n",
    "# test_x_c01 = np.concatenate((test_c0[:, :-2], test_c1[:, :-2]), axis=1)\n",
    "# test_y_c01 = np.concatenate((test_c0[:, -2:], test_c0[:, -2:]), axis=1)\n",
    "# dx = test_x_c01.reshape(-1, test_x_c01.shape[1], 1).astype('float32')\n",
    "# dy = tf.keras.utils.to_categorical(test_y_c01[:,0])\n",
    "# print(dy.shape, dx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9902, 920, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m = tf.keras.models.load_model(path+\"cnn_pl\"+\"/Model0.h5\")\n",
    "# cal_eg(m, dx, dy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EG graphs\n",
    "att= np.load(\"./eg_attributions/lstm_pl_eg.npy\")\n",
    "test_c0 = np.genfromtxt('./Data/test_patients_fc.csv', delimiter=',')\n",
    "test_c1 = np.genfromtxt('./Data/test_patients_sc.csv', delimiter=',')\n",
    "test_x_c01 = np.concatenate((test_c0[:, :-2], test_c1[:, :-2]), axis=1)\n",
    "test_y_c01 = np.concatenate((test_c0[:, -2:], test_c0[:, -2:]), axis=1)\n",
    "dx = test_x_c01.reshape(-1, test_x_c01.shape[1], 1).astype('float32')\n",
    "dy = tf.keras.utils.to_categorical(test_y_c01[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_att(att):\n",
    "    return (att-np.min(att))/(np.max(att)-np.min(att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att_maps(foldername, tname, class_l, title):\n",
    "    categories=['N','L','R','V','A','F','PN','P']\n",
    "    if tname==\"ph\":\n",
    "        # Loading data\n",
    "        test_y = np.load(\"./eval_data_10k/teset_y.npy\", allow_pickle=True)\n",
    "        test_x = np.load(\"./eval_data_10k/teset_x.npy\", allow_pickle=True)\n",
    "        atts = []\n",
    "        for i in range(1,11):\n",
    "            atts.append(np.array([normalise_att(i) for i in np.load(\"./eg_attributions/\"+foldername+\"/att\"+str(i)+\".npy\").squeeze()]))\n",
    "        indexes_for_class = [np.where(i==class_l) for i in test_y]\n",
    "        # class atts for each cv\n",
    "        atts_for_class = [atts[i][indexes_for_class[i][0]] for i in range(len(indexes_for_class))]\n",
    "        # mean atts for every cv\n",
    "        mean_atts_each_cv = np.array([np.mean(i, axis=0) for i in atts_for_class])\n",
    "        # mean atts of all cvs\n",
    "        mean_cv_atts = mean_atts_each_cv.mean(axis=0)\n",
    "        # getting signals for each cv\n",
    "        beats_for_class = [test_x[i][indexes_for_class[i][0]].squeeze() for i in range(len(indexes_for_class))]\n",
    "        # mean beat for every cv\n",
    "        mean_beats_each_cv = np.array([np.mean(i, axis=0) for i in beats_for_class])\n",
    "        # mean beat of all cvs\n",
    "        mean_cv_beat = mean_beats_each_cv.mean(axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(14,4), dpi=300)\n",
    "        plt.plot(mean_cv_beat)\n",
    "        plt.title(title)\n",
    "        plt.scatter(np.arange(len(mean_cv_beat)), mean_cv_beat, cmap='inferno_r', c=mean_cv_atts, s=50)\n",
    "        clim= np.ravel(mean_cv_atts)\n",
    "        plt.clim(min(clim),max(clim))\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"./images/attributions/\"+foldername+\"/\"+categories[class_l-1],dpi=300)\n",
    "        # print(\"./images/attributions/\"+foldername+\"/\"+categories[class_l-1])\n",
    "        plt.show()\n",
    "    elif tname==\"pl\":\n",
    "        # Loading data\n",
    "        test_c0 = np.genfromtxt('./Data/test_patients_fc.csv', delimiter=',')\n",
    "        test_c1 = np.genfromtxt('./Data/test_patients_sc.csv', delimiter=',')\n",
    "        test_x_c01 = np.concatenate((test_c0[:, :-2], test_c1[:, :-2]), axis=1)\n",
    "        test_y_c01 = np.concatenate((test_c0[:, -2:], test_c0[:, -2:]), axis=1)\n",
    "        dx = test_x_c01.reshape(-1, test_x_c01.shape[1], 1).astype('float32')\n",
    "        dy = tf.keras.utils.to_categorical(test_y_c01[:,0])\n",
    "        atts = np.array([normalise_att(i) for i in np.load(\"./eg_attributions/\"+foldername+\".npy\").squeeze()])\n",
    "        # Getting the indexes for the chosen class\n",
    "        indexes_for_class = np.where(test_y_c01==class_l)[0]\n",
    "        # Getting the attributions\n",
    "        atts_for_class = atts[indexes_for_class]\n",
    "        # Getting the beats\n",
    "        beats_for_class = dx[indexes_for_class].squeeze()\n",
    "        # Mean attribution\n",
    "        mean_atts = atts_for_class.mean(axis=0)\n",
    "        # Mean beat\n",
    "        mean_beat = beats_for_class.mean(axis=0)\n",
    "\n",
    "        plt.figure(figsize=(14,4), dpi=300)\n",
    "        plt.plot(mean_beat)\n",
    "        plt.title(title)\n",
    "        plt.scatter(np.arange(len(mean_beat)), mean_beat, cmap='inferno_r', c=mean_atts, s=50)\n",
    "        clim= np.ravel(mean_atts)\n",
    "        plt.clim(min(clim),max(clim))\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"./images/attributions/\"+foldername+\"/\"+categories[class_l-1],dpi=300)\n",
    "        # print(\"./images/attributions/\"+foldername+\"/\"+categories[class_l-1])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories=['N','L','R','V','A','F','f','P']\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 1, \"CNN - Beat holdout Attribution Map - Normal Beat (N)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 2, \"CNN - Beat holdout Attribution Map - LBBB Beat (L)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 3, \"CNN - Beat holdout Attribution Map - RBBB Beat (R)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 4, \"CNN - Beat holdout Attribution Map - Premature Ventricular Contraction (V)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 5, \"CNN - Beat holdout Attribution Map - Atrial Premature Beat (A)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 6, \"CNN - Beat holdout Attribution Map - Fused Ventricular & Normal Beat (F)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 7, \"CNN - Beat holdout Attribution Map - Fused Paced & Normal Beat (f)\")\n",
    "# get_att_maps(\"cnn_ph_eg\", \"ph\", 8, \"CNN - Beat holdout Attribution Map - Paced Beat (/)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 1, \"CNN - Patient leaveout Attribution Map - Normal Beat (N)\")\n",
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 2, \"CNN - Patient leaveout Attribution Map - LBBB Beat (L)\")\n",
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 3, \"CNN - Patient leaveout Attribution Map - RBBB Beat (R)\")\n",
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 4, \"CNN - Patient leaveout Attribution Map - Premature Ventricular Contraction (V)\")\n",
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 5, \"CNN - Patient leaveout Attribution Map - Atrial Premature Beat (A)\")\n",
    "# get_att_maps(\"cnn_pl_eg\", \"pl\", 8, \"CNN - Patient leaveout Attribution Map - Paced Beat (/)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 1, \"LSTM - Patient leaveout Attribution Map - Normal Beat (N)\")\n",
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 2, \"LSTM - Patient leaveout Attribution Map - LBBB Beat (L)\")\n",
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 3, \"LSTM - Patient leaveout Attribution Map - RBBB Beat (R)\")\n",
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 4, \"LSTM - Patient leaveout Attribution Map - Premature Ventricular Contraction (V)\")\n",
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 5, \"LSTM - Patient leaveout Attribution Map - Atrial Premature Beat (A)\")\n",
    "# get_att_maps(\"lstm_pl_eg\", \"pl\", 8, \"LSTM - Patient leaveout Attribution Map - Paced Beat (/)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ad3a160dbec8171a4c5fb2605380c0e08a4026dd895b943cd2f051981903870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ecg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
